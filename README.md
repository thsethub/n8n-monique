# ğŸ¤– MicroserviÃ§o de AnÃ¡lise e Preparo de Mensagens para IA

Este microserviÃ§o utiliza **FastAPI** para classificar e preparar mensagens inteligentemente antes de enviÃ¡-las para modelos de IA (OpenAI GPT), otimizando custos, performance e qualidade das respostas.

## ğŸ¯ Funcionalidades Principais

- **ClassificaÃ§Ã£o Inteligente**: Analisa mensagens e as categoriza em `system`, `user` ou `messages`
- **DetecÃ§Ã£o de IntegraÃ§Ãµes**: Identifica automaticamente quando APIs externas sÃ£o necessÃ¡rias (Google Calendar, Gmail, Drive, etc.)
- **Cache Inteligente**: Sistema de cache TTL que reduz drasticamente o tempo de resposta para mensagens similares
- **Logging Estruturado**: Logs em JSON para fÃ¡cil integraÃ§Ã£o com ferramentas de observabilidade
- **MÃ©tricas em Tempo Real**: ExposiÃ§Ã£o de mÃ©tricas de performance via endpoint `/metrics`

---

## ğŸ“‹ Endpoint Principal: `/preprocess`

### **POST** `/preprocess`

Este Ã© o endpoint mais importante do microserviÃ§o. Ele recebe uma mensagem do usuÃ¡rio, a classifica e prepara um payload otimizado para envio Ã  API do OpenAI.

### ğŸ”¹ Payload de Entrada

```json
{
  "message": "Preciso agendar uma reuniÃ£o com o time amanhÃ£ Ã s 14h",
  "ctx": {
    "lang": "pt",
    "temperature": 0.3,
    "model": "gpt-4o-mini"
  },
  "history": [
    {
      "role": "user",
      "content": "Oi"
    },
    {
      "role": "assistant",
      "content": "OlÃ¡! Como posso ajudar?"
    }
  ]
}
```

#### Campos do Payload:

| Campo | Tipo | ObrigatÃ³rio | DescriÃ§Ã£o |
|-------|------|-------------|-----------|
| `message` | `string` | âœ… Sim | A mensagem do usuÃ¡rio a ser analisada |
| `ctx.lang` | `string` | âŒ NÃ£o | Idioma (`pt` ou `en`). Se omitido, Ã© detectado automaticamente |
| `ctx.temperature` | `float` | âŒ NÃ£o | Temperatura base para o modelo (padrÃ£o: `0.3`) |
| `ctx.model` | `string` | âŒ NÃ£o | Modelo OpenAI a usar. Se omitido, Ã© selecionado automaticamente |
| `history` | `array` | âŒ NÃ£o | HistÃ³rico da conversa (Ãºltimas 3 mensagens sÃ£o usadas) |

---

### ğŸ”¸ Resposta (Exemplo 1: IntegraÃ§Ã£o de Sistema)

```json
{
  "message": "Preciso agendar uma reuniÃ£o com o time amanhÃ£ Ã s 14h",
  "ctx": {
    "lang": "pt",
    "temperature": 0.3
  },
  "history": [],
  "mensagem_completa": "Preciso agendar uma reuniÃ£o com o time amanhÃ£ Ã s 14h",
  "texto_normalizado": "preciso agendar uma reuniao com o time amanha as 14h",
  "openaiPayload": {
    "model": "gpt-4.1-mini",
    "messages": [
      {
        "role": "system",
        "content": "Responda em portuguÃªs do Brasil."
      },
      {
        "role": "system",
        "content": "MODO INTEGRAÃ‡ÃƒO ATIVO. A intenÃ§Ã£o do usuÃ¡rio parece ser usar ferramentas como calendÃ¡rio, documentos ou pagamentos. Antes de agir, sempre confirme os detalhes necessÃ¡rios. Informe que usaria as APIs (https://www.googleapis.com/auth/calendar) e peÃ§a confirmaÃ§Ã£o."
      },
      {
        "role": "user",
        "content": "Preciso agendar uma reuniÃ£o com o time amanhÃ£ Ã s 14h"
      }
    ],
    "temperature": 0.3,
    "max_tokens": 900
  },
  "classification": {
    "bucket": "system",
    "reasons": [
      "Palavras-chave de sistemas/APIs: reuniao, agendar"
    ],
    "scope": [
      "https://www.googleapis.com/auth/calendar"
    ]
  },
  "performance": {
    "extracao_ms": 0.05,
    "cache_lookup_ms": 0.12,
    "normalizacao_ms": 0.08,
    "classificacao_ms": 0.15,
    "construcao_payload_ms": 0.22,
    "total_ms": 0.62
  }
}
```

---

### ğŸ”¸ Resposta (Exemplo 2: Pergunta Direta)

```json
{
  "message": "Que dia Ã© hoje?",
  "mensagem_completa": "Que dia Ã© hoje?",
  "texto_normalizado": "que dia e hoje?",
  "openaiPayload": {
    "model": "gpt-4o-mini",
    "messages": [
      {
        "role": "system",
        "content": "Responda em portuguÃªs do Brasil."
      },
      {
        "role": "system",
        "content": "VocÃª Ã© um assistente no WhatsApp, amigÃ¡vel e direto. Evite jargÃµes. Se nÃ£o souber algo, admita e sugira como verificar."
      },
      {
        "role": "system",
        "content": "INSTRUÃ‡ÃƒO ADICIONAL: A mensagem Ã© uma pergunta direta. Responda de forma objetiva em 1 a 3 frases."
      },
      {
        "role": "user",
        "content": "Que dia Ã© hoje?"
      }
    ],
    "temperature": 0.2,
    "max_tokens": 400
  },
  "classification": {
    "bucket": "messages",
    "reasons": [
      "Pergunta direta/fechada detectada."
    ],
    "scope": []
  },
  "performance": {
    "extracao_ms": 0.03,
    "cache_lookup_ms": 0.08,
    "normalizacao_ms": 0.05,
    "classificacao_ms": 0.11,
    "construcao_payload_ms": 0.18,
    "total_ms": 0.45
  }
}
```

---

### âš¡ Performance e Tempo de Resposta

| CenÃ¡rio | Tempo MÃ©dio | ObservaÃ§Ã£o |
|---------|-------------|------------|
| **Cache Hit** | **~0.15ms** | Quando a mensagem jÃ¡ foi processada anteriormente |
| **Cache Miss (primeira vez)** | **0.4ms - 0.8ms** | Processamento completo da mensagem |
| **Mensagem complexa** | **0.6ms - 1.2ms** | Mensagens longas ou com mÃºltiplas intenÃ§Ãµes |
| **Com histÃ³rico (3 msgs)** | **+0.1ms - 0.2ms** | Overhead adicional para processar histÃ³rico |

**Taxa de Cache Hit esperada:** 40-60% em produÃ§Ã£o (depende do padrÃ£o de uso)

**ObservaÃ§Ã£o:** Os tempos acima **NÃƒO incluem** a latÃªncia de rede ou o tempo de resposta da API do OpenAI. SÃ£o apenas os tempos de prÃ©-processamento.

---

### ğŸ“Š Campos da Resposta

#### `classification.bucket`
Indica a categoria da mensagem:
- **`system`**: Requer integraÃ§Ã£o com APIs externas (Google, pagamentos, etc.)
- **`messages`**: Pergunta direta e objetiva
- **`user`**: Mensagem complexa que requer contexto e personalizaÃ§Ã£o

#### `classification.scope`
Array com os escopos OAuth necessÃ¡rios para executar a aÃ§Ã£o (apenas para `bucket: "system"`):
- `https://www.googleapis.com/auth/calendar` - Google Calendar
- `https://mail.google.com/` - Gmail
- `https://www.googleapis.com/auth/drive` - Google Drive
- `https://www.googleapis.com/auth/spreadsheets` - Google Sheets
- `boleto` - Sistema de geraÃ§Ã£o de boletos

#### `openaiPayload`
Payload pronto para ser enviado diretamente Ã  API do OpenAI, contendo:
- **Prompts de sistema otimizados** baseados na classificaÃ§Ã£o
- **Modelo selecionado automaticamente** (ou o especificado no `ctx.model`)
- **ParÃ¢metros ajustados** (`temperature`, `max_tokens`)

#### `performance`
MÃ©tricas detalhadas de latÃªncia por etapa do processamento (em milissegundos)

---

## ğŸš€ Como Rodar Localmente

### 1. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

### 2. Execute a API:
```bash
uvicorn app.main:app --reload --port 8181
```

### 3. Acesse a documentaÃ§Ã£o interativa:
- Swagger UI: http://localhost:8181/docs
- ReDoc: http://localhost:8181/redoc

### 4. Teste o endpoint:
```bash
curl -X POST http://localhost:8181/preprocess \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Preciso criar uma planilha com os dados de vendas",
    "ctx": {"lang": "pt"}
  }'
```

---

## ğŸ³ Docker

### Build da imagem:
```bash
docker build -t preproc-api:latest .
```

### Executar container:
```bash
docker run -p 8181:8181 preproc-api:latest
```

---

## ğŸ“ Estrutura do Projeto

```
n8n-monique/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py          # Endpoints da API
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py          # ConfiguraÃ§Ã£o do logging estruturado
â”‚   â”‚   â”œâ”€â”€ metrics.py         # MÃ©tricas e cache global
â”‚   â”‚   â””â”€â”€ middleware.py      # Middleware de logging de latÃªncia
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py         # Schemas Pydantic (futuro)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ analisador/         # ğŸ“¦ MÃ“DULO MODULAR (8 componentes)
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ analisador_principal.py    # OrquestraÃ§Ã£o
â”‚   â”‚       â”œâ”€â”€ classificador.py           # ClassificaÃ§Ã£o
â”‚   â”‚       â”œâ”€â”€ construtor_payload.py      # Payload OpenAI
â”‚   â”‚       â”œâ”€â”€ detector_scopes.py         # DetecÃ§Ã£o de scopes
â”‚   â”‚       â”œâ”€â”€ detector_idioma.py         # DetecÃ§Ã£o de idioma
â”‚   â”‚       â”œâ”€â”€ gerenciador_cache.py       # OperaÃ§Ãµes de cache
â”‚   â”‚       â”œâ”€â”€ normalizador.py            # NormalizaÃ§Ã£o de texto
â”‚   â”‚       â”œâ”€â”€ constantes.py              # Constantes
â”‚   â”‚       â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do mÃ³dulo
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ regex.py           # Regex prÃ©-compiladas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                # Ponto de entrada FastAPI
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ pytest.ini
â”‚   â””â”€â”€ test_main.py
â”œâ”€â”€ docs/
â”œâ”€â”€ main.py                    # Importa app de app.main
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Outros Endpoints

### **GET** `/health`
Verifica o status do serviÃ§o.

**Resposta:**
```json
{
  "status": "healthy",
  "service": "preproc-api",
  "version": "2.0.0",
  "timestamp": 1697654321.123
}
```

---

### **GET** `/metrics`
Retorna mÃ©tricas de performance em tempo real.

**Resposta:**
```json
{
  "total_requests": 1523,
  "cache_hits": 687,
  "cache_misses": 836,
  "cache_hit_rate_percent": 45.11,
  "cache_size": 234,
  "avg_latency_ms": 0.58,
  "error_count": 3,
  "error_rate_percent": 0.20,
  "timestamp": 1697654321.456
}
```

---

### **POST** `/webhook`
Endpoint simplificado para receber mensagens via webhook (ex: ngrok, Evolution API).

**Request:**
```json
{
  "from": "5511999999999",
  "message": "agendar reuniÃ£o amanhÃ£"
}
```

---

## ğŸ§ª Testes

Execute os testes com pytest:

```bash
pytest tests/ -v --cov=app --cov-report=html
```

**Cobertura esperada:** >85%

---

## ğŸ”§ VariÃ¡veis de Ambiente (Futuro)

| VariÃ¡vel | PadrÃ£o | DescriÃ§Ã£o |
|----------|--------|-----------|
| `CACHE_TTL` | `3600` | Tempo de vida do cache em segundos |
| `CACHE_MAX_SIZE` | `1000` | Tamanho mÃ¡ximo do cache |
| `LOG_LEVEL` | `INFO` | NÃ­vel de log (DEBUG, INFO, WARNING, ERROR) |

---

## ğŸ“ Roadmap

- [ ] Adicionar Pydantic models para validaÃ§Ã£o de entrada
- [ ] Implementar rate limiting
- [ ] Adicionar suporte a mÃºltiplos idiomas (ES, FR)
- [ ] IntegraÃ§Ã£o com Redis para cache distribuÃ­do
- [ ] Implementar circuit breaker para APIs externas
- [ ] Adicionar testes de integraÃ§Ã£o
- [ ] DocumentaÃ§Ã£o de arquitetura (diagramas)

---

## ğŸ“„ LicenÃ§a

MIT License - Sinta-se livre para usar e modificar.

---

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request
